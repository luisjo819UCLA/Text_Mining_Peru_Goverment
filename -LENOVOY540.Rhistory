V(network)$degree <- strength(graph = network)
E(network)$width <- E(network)$weight/max(E(network)$weight)
library(networkD3)
library(magrittr)
network.D3 <- igraph_to_networkD3(g = network)
# Define node size.
network.D3$nodes %<>% mutate(Degree = (1E-2)*V(network)$degree)
# Degine color group (I will explore this feature later).
network.D3$nodes %<>% mutate(Group = 1)
# Define edges width.
network.D3$links$Width <- 10*E(network)$width
forceNetwork(
Links = network.D3$links,
Nodes = network.D3$nodes,
Source = 'source',
Target = 'target',
NodeID = 'name',
Group = 'Group',
opacity = 0.9,
Value = 'Width',
Nodesize = 'Degree',
# We input a JavaScript function.
linkWidth = JS("function(d) { return Math.sqrt(d.value); }"),
fontSize = 15,
zoom = TRUE,
opacityNoHover = 1,
linkDistance = 45,
arrows = TRUE
)
#El top 3 por partido
tidy_detalle %>%
group_by(Partido) %>%
count(word,sort=TRUE) %>%
top_n(3,n) %>%
arrange(Partido,-n)
#Proceso la data para graficarla
p = tidy_detalle%>%
group_by(Partido) %>% #Agrupo por partido
count(word, sort = TRUE)  %>%  #Cuento las palabras
top_n(15,n) %>% #Me quedo con el top 15
mutate(word = reorder(str_to_title(word), n)) %>% #Le pongo mayuscula al inicio
ungroup() %>%
arrange(Partido,n) %>% #Ordeno por partido y numero
mutate(order = row_number()) #El orden (para el gráfico)
#grafico con GGPLOT
p %>%
ggplot(aes(order, n)) +
geom_col() +
xlab(NULL) +
coord_flip() +
facet_wrap(~Partido,scales = "free") +
scale_x_continuous(
breaks = p$order,
labels = p$word,
expand=c(0,0)
) +
theme_wsj() +
theme(strip.text.x = element_text(size = 12, face ="bold",colour = "black"))
#El top 3 por partido
tidy_detalle %>%
group_by(Partido) %>%
count(word,sort=TRUE) %>%
top_n(3,n) %>%
arrange(Partido,-n)
shiny::runApp('app')
runApp()
runApp()
library(shiny)
library("pdftools")
library(tidyverse)
library(tidytext)
library(GGally)
library(ggthemes)
#Primero llamo a los planes de gobierno en PDF
Fuerza_Popular = pdf_data("Data/Fuerza_popular.PDF")
Partido_Morado= pdf_data("Data/Partido_morado.PDF")
Accion_Popular = pdf_data("Data/Accion_popular(peor_partido).PDF")
JP = pdf_data("Data/Juntos_por_Peru(JP).PDF")
Somos_Peru = pdf_data("Data/Somos_peru.PDF")
Victoria_Nacional = pdf_data("Data/Victoria_nacional.PDF")
cosas = objects()  #los nombres de todas las variables en el environment
#Elimino todas las variables que no sean "z"
rm(list=setdiff(ls(),"z"))
#Luego los trato de agrupar
z = tibble() #Base de datos vacia
#Ahora, sumaré todos los planes de gobierno (y sus hojas) en una sola base de
#datos
for (i in cosas[cosas!="z"]){
x = get(i)
for(j in 1:length(x)){
if(j==1){
z1 = tibble(x[[j]]["text"],Hoja = j,Partido = i)
z = bind_rows(z,z1)
}else{
z = x[[j]]["text"] %>%
tibble(Hoja = j,Partido=i) %>%
{bind_rows(z,.)}
}
}
}
library(shiny)
library("pdftools")
library(tidyverse)
library(tidytext)
library(GGally)
library(ggthemes)
#Primero llamo a los planes de gobierno en PDF
Fuerza_Popular = pdf_data("Data/Fuerza_popular.PDF")
Partido_Morado= pdf_data("Data/Partido_morado.PDF")
Accion_Popular = pdf_data("Data/Accion_popular(peor_partido).PDF")
JP = pdf_data("Data/Juntos_por_Peru(JP).PDF")
Somos_Peru = pdf_data("Data/Somos_peru.PDF")
Victoria_Nacional = pdf_data("Data/Victoria_nacional.PDF")
#Luego los trato de agrupar
z = tibble() #Base de datos vacia
cosas = objects()  #los nombres de todas las variables en el environment
#Ahora, sumaré todos los planes de gobierno (y sus hojas) en una sola base de
#datos
for (i in cosas[cosas!="z"]){
x = get(i)
for(j in 1:length(x)){
if(j==1){
z1 = tibble(x[[j]]["text"],Hoja = j,Partido = i)
z = bind_rows(z,z1)
}else{
z = x[[j]]["text"] %>%
tibble(Hoja = j,Partido=i) %>%
{bind_rows(z,.)}
}
}
}
#Elimino todas las variables que no sean "z"
rm(list=setdiff(ls(),"z"))
#El procesamiento####
#Primero convoco a las stop_words (palabras inútiles)
stop_words = read.table("Stopwords.txt",encoding = "UTF-8") %>%
rename("word" = V1) %>%
mutate(word = as.character(word)) %>%
add_row(word=c("año")) %>% #Añades palabras inutiles según el contexto (y los resultados)
as_tibble()
#Proceso el acumulado de planes de gobierno
tidy_detalle = z %>%
unnest_tokens(word,text) %>% #Función unnest, cada palabra es una observación (sin signos)
anti_join(stop_words) %>% #Elimino stop words
filter(grepl("^[A-Za-z]+$",word)) #Solo palabras (sin numeros ni signos)
tidy_lineas = z %>%
group_by(Partido) %>%
summarise(text = paste(text,collapse = " ")) %>%
unnest_tokens(output = word,token = "regex",text,pattern = "(?<=\\.)\\s+")
# Sentimientos
sentiment  = readxl::read_excel("dictionary.xlsx") %>%
rename("word" = "term") %>%
filter(word!="mil" & word!="popular" & word!="victoria")
palabras_sentimiento = tidy_detalle %>%
inner_join(sentiment) %>%
mutate(score = ifelse(score_pos=="1","Positivo","Negativo")) %>%
count(word,score,sort=TRUE)
omision2 = tibble(bigram = c("partido morado","fuerza popular",
"victoria nacional","acción popular",
"sua ama","llulla ama",
"morado propone","ingreso 15",
"expuesto proponemos",
"sentido proponemos",
"indicadores porcentaje","objetivos indicadores",
"pbi 1.1","pilar estratégico","20 mil","mil soles","mil habitantes",
"indicadores número","identificados objetivos","problemas identificados",
"metas 2021","lineamientos generales","indicadores metas",
"problema indicadores","metas contar","situación actual",
"físico legal","alto corresponde","porcentual anual",
"política política"))
omision3 = tibble(word=c("mmm","ii","alta","altas","inclusive",
"mil","etc","art","partido","haga","forma",
"asimismo","alcance","camino","vii"))
frecuenia = tidy_detalle%>%
count(Partido, word) %>%
group_by(Partido) %>%
mutate(proportion = n / sum(n)) %>%
select(-n) %>%
anti_join(omision3)
View(frecuenia)
frecuenia %>%
pivot_wider(word,names_from=Partido,values_from=proportion)
p80 = frecuenia %>%
filter(Partido = "Partido_Morado") %>%
pivot_wider(word,names_from=Partido,values_from=proportion)
p80 = frecuenia %>%
filter(Partido == "Partido_Morado") %>%
pivot_wider(word,names_from=Partido,values_from=proportion)
p80%>%
select(-word) %>%
ggpairs(diag=list(continuous = "autopointDiag"),
lower = list(continuous =
function(data,mapping,...){
ggplot(data = data,mapping=mapping) +
geom_abline(color="gray20",lty = 2) +
geom_jitter(alpha=0.1,size=2.5,width = 0.3,height = 0.3,colour="gray75") +
geom_text(aes(label = p80$word), check_overlap = TRUE, vjust = 1.5,size=2,colour="red") +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
theme_minimal()
}))
p80 = frecuenia %>%
filter(Partido == "Partido_Morado" | Partido == "JP") %>%
pivot_wider(word,names_from=Partido,values_from=proportion)
p80%>%
select(-word) %>%
ggpairs(diag=list(continuous = "autopointDiag"),
lower = list(continuous =
function(data,mapping,...){
ggplot(data = data,mapping=mapping) +
geom_abline(color="gray20",lty = 2) +
geom_jitter(alpha=0.1,size=2.5,width = 0.3,height = 0.3,colour="gray75") +
geom_text(aes(label = p80$word), check_overlap = TRUE, vjust = 1.5,size=2,colour="red") +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
theme_minimal()
}))
ggplot(data = data,mapping=mapping) +
geom_abline(color="gray20",lty = 2) +
geom_jitter(alpha=0.1,size=2.5,width = 0.3,height = 0.3,colour="gray75") +
geom_text(aes(label = p80$word), check_overlap = TRUE, vjust = 1.5,size=3,colour="red") +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
theme_minimal()
ggplot(data = data,mapping=mapping) +
geom_abline(color="gray20",lty = 2) +
geom_jitter(alpha=0.1,size=2.5,width = 0.3,height = 0.3,colour="gray75") +
geom_text(aes(label = p80$word), check_overlap = TRUE, vjust = 1.5,size=3,colour="red") +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
theme_minimal()
p80%>%
select(-word) %>%
ggpairs(diag=list(continuous = "autopointDiag"),
lower = list(continuous =
function(data,mapping,...){
ggplot(data = data,mapping=mapping) +
geom_abline(color="gray20",lty = 2) +
geom_jitter(alpha=0.1,size=2.5,width = 0.3,height = 0.3,colour="gray75") +
geom_text(aes(label = p80$word), check_overlap = TRUE, vjust = 1.5,size=3,colour="red") +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
theme_minimal()
}))
today()
?rmarkdown::html_document
knitr::opts_chunk$set(fig.width=12,
fig.height=8,
fig.path='Figs/',
echo=FALSE,
warning=FALSE,
message=FALSE)
library("pdftools")
library(tidyverse)
library(tidytext)
library(GGally)
library(ggplot2)
library(ggthemes)
library(scales)
library(reshape2)
library(wordcloud)
library(wordcloud2)
library(RColorBrewer)
#setwd(dirname(rstudioapi::getSourceEditorContext()$path))
rm(list=ls())
library(pdftools)
library(tidyverse)
library(tidytext)
library(GGally)
library(ggthemes)
library(widyr)
library(igraph)
library(wordcloud)
library(wordcloud2)
library(RColorBrewer)
library(scales)
library(ggraph)
library(tidygraph)
library(reshape2)
# Chunk 1
knitr::opts_chunk$set(fig.width=12,
fig.height=8,
fig.path='Figs/',
echo=FALSE,
warning=FALSE,
message=FALSE)
# Chunk 2
library("pdftools")
library(tidyverse)
library(tidytext)
library(GGally)
library(ggplot2)
library(ggthemes)
library(scales)
library(reshape2)
library(wordcloud)
library(wordcloud2)
library(RColorBrewer)
#setwd(dirname(rstudioapi::getSourceEditorContext()$path))
rm(list=ls())
# Chunk 3
library(pdftools)
library(tidyverse)
library(tidytext)
library(GGally)
library(ggthemes)
library(widyr)
library(igraph)
library(wordcloud)
library(wordcloud2)
library(RColorBrewer)
library(scales)
library(ggraph)
library(tidygraph)
library(reshape2)
# Chunk 4
#Primero llamo a los planes de gobierno en PDF
Fuerza_Popular = pdf_data("Data/Fuerza_popular.PDF")
Partido_Morado= pdf_data("Data/Partido_morado.PDF")
Accion_Popular = pdf_data("Data/Accion_popular(peor_partido).PDF")
JP = pdf_data("Data/Juntos_por_Peru(JP).PDF")
Somos_Peru = pdf_data("Data/Somos_peru.PDF")
Victoria_Nacional = pdf_data("Data/Victoria_nacional.PDF")
#Luego los trato de agrupar
z = tibble() #Base de datos vacia
cosas = objects()  #los nombres de todas las variables en el environment
#Ahora, sumaré todos los planes de gobierno (y sus hojas) en una sola base de
#datos
for (i in cosas[cosas!="z"]){
x = get(i)
for(j in 1:length(x)){
if(j==1){
z1 = tibble(x[[j]]["text"],Hoja = j,Partido = i)
z = bind_rows(z,z1)
}else{
z = x[[j]]["text"] %>%
tibble(Hoja = j,Partido=i) %>%
{bind_rows(z,.)}
}
}
}
#Elimino todas las variables que no sean "z"
rm(list=setdiff(ls(),"z"))
#El procesamiento####
#Primero convoco a las stop_words (palabras inútiles)
stop_words = read.table("Stopwords.txt",encoding = "UTF-8") %>%
rename("word" = V1) %>%
mutate(word = as.character(word)) %>%
add_row(word=c("año")) %>% #Añades palabras inutiles según el contexto (y los resultados)
as_tibble()
#Proceso el acumulado de planes de gobierno
tidy_detalle = z %>%
unnest_tokens(word,text) %>% #Función unnest, cada palabra es una observación (sin signos)
anti_join(stop_words) %>% #Elimino stop words
filter(grepl("^[A-Za-z]+$",word)) #Solo palabras (sin numeros ni signos)
tidy_lineas = z %>%
group_by(Partido) %>%
summarise(text = paste(text,collapse = " ")) %>%
unnest_tokens(output = word,token = "regex",text,pattern = "(?<=\\.)\\s+")
# Sentimientos
sentiment  = readxl::read_excel("dictionary.xlsx") %>%
rename("word" = "term") %>%
filter(word!="mil" & word!="popular" & word!="victoria")
palabras_sentimiento = tidy_detalle %>%
inner_join(sentiment) %>%
mutate(score = ifelse(score_pos=="1","Positivo","Negativo")) %>%
count(word,score,sort=TRUE)
#Bigramas
omision2 = tibble(bigram = c("partido morado","fuerza popular",
"victoria nacional","acción popular",
"sua ama","llulla ama",
"morado propone","ingreso 15",
"expuesto proponemos",
"sentido proponemos",
"indicadores porcentaje","objetivos indicadores",
"pbi 1.1","pilar estratégico","20 mil","mil soles","mil habitantes",
"indicadores número","identificados objetivos","problemas identificados",
"metas 2021","lineamientos generales","indicadores metas",
"problema indicadores","metas contar","situación actual",
"físico legal","alto corresponde","porcentual anual",
"política política"))
# Chunk 5
tidy_detalle %>%
count(word,sort=TRUE) %>%
top_n(5,n)
# Chunk 6
tidy_detalle %>%
count(word,sort = TRUE) %>%
wordcloud2(size=1,fontWeight = "bold",color="random-dark",minSize = "Hola todos",
maxRotation = pi/9,minRotation = -pi/9)
knitr::opts_chunk$set(fig.width=12,
fig.height=8,
fig.path='Figs/',
echo=FALSE,
warning=FALSE,
message=FALSE)
library("pdftools")
library(tidyverse)
library(tidytext)
library(GGally)
library(ggplot2)
library(ggthemes)
library(scales)
library(reshape2)
library(wordcloud)
library(wordcloud2)
library(RColorBrewer)
#setwd(dirname(rstudioapi::getSourceEditorContext()$path))
library(pdftools)
library(tidyverse)
library(tidytext)
library(GGally)
library(ggthemes)
library(widyr)
library(igraph)
library(wordcloud)
library(wordcloud2)
library(RColorBrewer)
library(scales)
library(ggraph)
library(tidygraph)
library(reshape2)
#Primero llamo a los planes de gobierno en PDF
Fuerza_Popular = pdf_data("Data/Fuerza_popular.PDF")
Partido_Morado= pdf_data("Data/Partido_morado.PDF")
Accion_Popular = pdf_data("Data/Accion_popular(peor_partido).PDF")
JP = pdf_data("Data/Juntos_por_Peru(JP).PDF")
Somos_Peru = pdf_data("Data/Somos_peru.PDF")
Victoria_Nacional = pdf_data("Data/Victoria_nacional.PDF")
#Luego los trato de agrupar
z = tibble() #Base de datos vacia
cosas = objects()  #los nombres de todas las variables en el environment
#Ahora, sumaré todos los planes de gobierno (y sus hojas) en una sola base de
#datos
for (i in cosas[cosas!="z"]){
x = get(i)
for(j in 1:length(x)){
if(j==1){
z1 = tibble(x[[j]]["text"],Hoja = j,Partido = i)
z = bind_rows(z,z1)
}else{
z = x[[j]]["text"] %>%
tibble(Hoja = j,Partido=i) %>%
{bind_rows(z,.)}
}
}
}
#Elimino todas las variables que no sean "z"
rm(list=setdiff(ls(),"z"))
#El procesamiento####
#Primero convoco a las stop_words (palabras inútiles)
stop_words = read.table("Stopwords.txt",encoding = "UTF-8") %>%
rename("word" = V1) %>%
mutate(word = as.character(word)) %>%
add_row(word=c("año")) %>% #Añades palabras inutiles según el contexto (y los resultados)
as_tibble()
#Proceso el acumulado de planes de gobierno
tidy_detalle = z %>%
unnest_tokens(word,text) %>% #Función unnest, cada palabra es una observación (sin signos)
anti_join(stop_words) %>% #Elimino stop words
filter(grepl("^[A-Za-z]+$",word)) #Solo palabras (sin numeros ni signos)
tidy_lineas = z %>%
group_by(Partido) %>%
summarise(text = paste(text,collapse = " ")) %>%
unnest_tokens(output = word,token = "regex",text,pattern = "(?<=\\.)\\s+")
# Sentimientos
sentiment  = readxl::read_excel("dictionary.xlsx") %>%
rename("word" = "term") %>%
filter(word!="mil" & word!="popular" & word!="victoria")
palabras_sentimiento = tidy_detalle %>%
inner_join(sentiment) %>%
mutate(score = ifelse(score_pos=="1","Positivo","Negativo")) %>%
count(word,score,sort=TRUE)
#Bigramas
omision2 = tibble(bigram = c("partido morado","fuerza popular",
"victoria nacional","acción popular",
"sua ama","llulla ama",
"morado propone","ingreso 15",
"expuesto proponemos",
"sentido proponemos",
"indicadores porcentaje","objetivos indicadores",
"pbi 1.1","pilar estratégico","20 mil","mil soles","mil habitantes",
"indicadores número","identificados objetivos","problemas identificados",
"metas 2021","lineamientos generales","indicadores metas",
"problema indicadores","metas contar","situación actual",
"físico legal","alto corresponde","porcentual anual",
"política política"))
tidy_detalle %>%
count(word,sort=TRUE) %>%
top_n(5,n)
tidy_detalle %>%
count(word,sort = TRUE) %>%
wordcloud2(size=1,fontWeight = "bold",color="random-dark",minSize = "Hola todos",
maxRotation = pi/9,minRotation = -pi/9)
?wordcloud2
install.packages("tint")
?render()
?html_document
library(tint)
install.packages("hrbrthemes")
library(hrhrthemes)
library(hbhrthemes)
library(hrbrthemes)
hrbrthemes::import_roboto_condensed()
library(tint)
rmarkdown:::themes()
?tint
